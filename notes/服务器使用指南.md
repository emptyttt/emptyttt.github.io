# 服务器使用指南

作者：Anna

## **使用vscode的ssh连接远程服务器**

在扩展里面下载ssh远程连接的扩展

**Vscode 终端**里面输入

```
ssh name@ip
```

或者

```
ssh -o PreferredAuthentications=password -o PubkeyAuthentication=no name@ip
```

强制密码登陆

在远程服务器上**查看服务器的用户名**

```
whoami
```

**查看服务器的ip地址**

```
ip add
```

或者

```
ifconfig
```

找到inet 192.168.x.x或者10.x.x.x为内网ip

## **显卡使用**

```
nvidia-smi
```

![image-20250907170635331](/Users/tanliuna/Library/Application Support/typora-user-images/image-20250907170635331.png)

![img_v3_02pt_c38f28db-37e3-4338-9355-a691794b7c0g](/Users/tanliuna/Library/Containers/com.bytedance.macos.feishu/Data/Library/Application Support/LarkShell/sdk_storage/6983d1c213308ac52eb46eaeb1cc59dd/resources/images/img_v3_02pt_c38f28db-37e3-4338-9355-a691794b7c0g.jpg)

------

**GPU / Fan / Temp / Perf**

- **GPU**：GPU 的编号（0,1,2…）。
- **Fan**：风扇转速，通常是百分比。
- **Temp**：GPU 温度（摄氏度）。
- **Perf**：性能状态 (Performance State, P-State)，数值越小代表性能状态越高：
  - P0 = 最高性能模式
  - P8 = 空闲/低功耗

**Persistence-M / Pwr:Usage/Cap**

- **Persistence-M**：Persistence Mode，是否开启“持久模式”。开启后即使没有任务运行，驱动也会保持加载，减少首次调用延迟。
- **Pwr:Usage/Cap**：当前功耗 / 功耗上限（瓦）。
  - 例如 150W / 250W 表示当前 150 瓦，最大 250 瓦。

**Bus-Id / Disp.A**

- **Bus-Id**：PCI 总线 ID，用来区分不同物理 GPU。
- **Disp.A**：Display Active，是否有显示设备在用这块 GPU（比如连显示器）。
  - On：这块卡在输出画面。
  - Off：纯计算卡。

**Memory-Usage**：显存使用情况（已用 / 总量）。

- 例如 4096MiB / 24576MiB，表示用了 4G，在 24G 总显存里。

**Volatile Uncorr. ECC**：ECC 错误计数（Error Correcting Code）。

- 如果卡支持 ECC，会显示累计的不可修复错误次数。
- 一般科研/深度学习用的消费卡（如 RTX 3090）是 N/A。

**GPU-Util**：GPU 核心的利用率（%）。

- 100% 表示满载计算。
- 0% 表示空闲。
- 训练模型时这项通常在 90% 左右波动。

**Compute M. / MIG M.**

- **Compute M. (Compute Mode)**：计算模式。
  - Default：允许多个进程共享 GPU。
  - Exclusive_Process：一次只允许一个进程使用。
- **MIG M. (Multi-Instance GPU Mode)**：是否启用 MIG（A100/H100 的 GPU 分区功能）。
  - Enabled 表示 GPU 可以被拆分成多个小 GPU 实例。
  - 普通显卡显示 N/A。

- **温度 / 风扇 / 功耗** → 硬件运行状态。
- **显存使用 / GPU-Util** → 任务是否占满 GPU。
- **Perf / Compute Mode / MIG** → 调度策略。
- **ECC** → 稳定性检测。

------

**确认进程是否已终止**检查是否还有残留的 Python 进程：

```
ps aux | grep python
```

如果没有看到与训练相关的进程，说明已经成功终止。

------

这会显示整个 GPU 1 的表格，包括运行的进程。适合观察训练进程的显存变化。

```
watch -n1 "nvidia-smi -i 1"
```

------



```
watch -n1 "nvidia-smi -i 1 --query-gpu=memory.used,memory.total --format=csv,noheader,nounits"
```



## 配置环境

查看文档 [conda虚拟环境中安装cuda和cudnn，再也不用头疼版本号的问题了](https://blog.csdn.net/qq_43705697/article/details/121618276)

**具体步骤**（注意：如果是第一次安装anaconda，需要先修改镜像要先使用命令把conda环境激活到你想要安装的那个环境。）

```
conda activate name
```

查看conda支持的cuda版本：查找源内所有的cuda版本，以及下载地址，如图所示

```
conda search cudatoolkit --info
```

<img src="https://i-blog.csdnimg.cn/blog_migrate/b8383107c2d06d5c7f9e91b7c5ca1f68.png" alt="在这里插入图片描述" style="zoom: 67%;" />


下载cuda：找到自己想要的cuda版本后，先把cuda下载到本地。首先复制url字段里的下载链接，然后用命令cd到想要下载的目录，执行如下代码下载

```
wget 你刚刚复制的链接地址
```

安装cuda：执行如下命令进行安装，因为是通过本地安装的，所以需要写明本地包的路径

```
conda install --use-local 本地cuda包所在的路径
```

查看cuda对应的cudnn版本：使用如下命令查看conda支持的cudnn版本，注意cudnn的版本一定要和刚刚下载的cuda版本对应

```
conda search cudnn --info
```

执行后的结果如图所示，图中标出了cudnn所对应的cuda版本号位置

<img src="https://i-blog.csdnimg.cn/blog_migrate/0a357c1456760ef7fe59dc58d0168213.png" alt="在这里插入图片描述" style="zoom:67%;" />

下载cudnn版本：还是复制你想要版本的cudnn的下载地址，使用

```
wget 链接地址进行下载
```

安装cudnn

```
conda install --use-local 本地cudnn包所在的路径
```

测试安装是否成功
在虚拟环境中安装完cuda和cudnn想要测试是否安装成功，不能使用nvcc -V命令测试，需要在虚拟环境中安装pytorch包进行测试

**安装pytorch**
**首先安装与cuda相匹配的pytorch和torchvision包，可以去[pytorch官网](https://blog.csdn.net/qq_43705697/article/details/121618276#:~:text=%E5%8C%85%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%8E%BB-,pytorch%E5%AE%98%E7%BD%91,-%E6%9F%A5%E8%AF%A2%E3%80%82)查询。**

测试cuda版本
装好pytorch后，命令行输入

```
python
```

进入python的命令行，导入torch包

```
import torch
```

查询cuda版本

```
print(torch.version.cuda)
```

查询cudnn版本

```
print(torch.backends.cudnn.version())
```

原文链接：https://blog.csdn.net/qq_43705697/article/details/121618276